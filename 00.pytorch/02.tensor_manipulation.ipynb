{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a7d9a80-a7e4-43bb-af64-e04d949d0235",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f309184e-5a1d-463b-997e-6a4e0ab0cb55",
   "metadata": {},
   "source": [
    "## Manipulating Tensors in Pytorch\n",
    "\n",
    "### Indexing\n",
    "Just as in numpy, elements in a tensor can be accessed by index. As in any numpy array, the first element has index 0 and ranges are specified to include the first to last_element-1. We can access elements according to their relative position to the end of the list by using negative indices. Indexing is also referred to as slicing.\n",
    "\n",
    "For example, [-1] selects the last element; [1:3] selects the second and the third elements, and [:-2] will select all elements excluding the last and second-to-last elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5026549-c1ed-4d65-ad13-0c8b8d262e61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(0,10)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dae87456-f7db-486a-b064-f077171ef2ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(9)\n",
      "tensor([1, 2])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6, 7])\n"
     ]
    }
   ],
   "source": [
    "print(x[-1])\n",
    "print(x[1:3])\n",
    "print(x[:-2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa21759b-ecc2-4f03-868c-95ef1c3dffc6",
   "metadata": {},
   "source": [
    "When we have multidimensional tensors, indexing rules work the same way as NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f52fcc1-342e-43b5-a795-9e61a27f9986",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[[0.6052, 0.9500, 0.6122, 0.8043, 0.8604],\n",
       "           [0.4410, 0.3089, 0.3415, 0.1730, 0.4359],\n",
       "           [0.1127, 0.1262, 0.3026, 0.7474, 0.0304],\n",
       "           [0.3562, 0.1015, 0.6013, 0.0753, 0.3767]],\n",
       "\n",
       "          [[0.7739, 0.6223, 0.4113, 0.5697, 0.4754],\n",
       "           [0.8438, 0.4443, 0.3628, 0.8503, 0.0903],\n",
       "           [0.9975, 0.8044, 0.1481, 0.0114, 0.1434],\n",
       "           [0.0310, 0.6013, 0.6739, 0.7435, 0.7067]],\n",
       "\n",
       "          [[0.5022, 0.0317, 0.7890, 0.6018, 0.9796],\n",
       "           [0.1295, 0.8435, 0.4962, 0.5049, 0.2748],\n",
       "           [0.0506, 0.2356, 0.3276, 0.3444, 0.6352],\n",
       "           [0.2016, 0.6140, 0.0890, 0.5393, 0.0902]]],\n",
       "\n",
       "\n",
       "         [[[0.1199, 0.3958, 0.5205, 0.9517, 0.1954],\n",
       "           [0.8870, 0.4473, 0.8225, 0.3530, 0.8856],\n",
       "           [0.5188, 0.0591, 0.7742, 0.7723, 0.6346],\n",
       "           [0.4128, 0.6335, 0.9946, 0.2659, 0.8958]],\n",
       "\n",
       "          [[0.7701, 0.5681, 0.2744, 0.7417, 0.5187],\n",
       "           [0.8333, 0.7371, 0.7043, 0.0288, 0.0458],\n",
       "           [0.6413, 0.1105, 0.9185, 0.2973, 0.8442],\n",
       "           [0.0176, 0.7071, 0.8612, 0.1675, 0.8374]],\n",
       "\n",
       "          [[0.4098, 0.8697, 0.8486, 0.6932, 0.4094],\n",
       "           [0.4707, 0.0578, 0.1890, 0.2390, 0.2479],\n",
       "           [0.4148, 0.3162, 0.8039, 0.9945, 0.1395],\n",
       "           [0.1556, 0.1367, 0.6546, 0.0030, 0.3008]]]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(1, 2, 3, 4, 5)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f21a3add-3f1c-4117-b978-2f0e58e5b140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " shape of x:torch.Size([1, 2, 3, 4, 5])\n",
      " shape of x[0]:torch.Size([2, 3, 4, 5])\n",
      " shape of x[0][0]:torch.Size([3, 4, 5])\n",
      " shape of x[0][0][0]:torch.Size([4, 5])\n"
     ]
    }
   ],
   "source": [
    "print(f\" shape of x:{x.shape}\")\n",
    "print(f\" shape of x[0]:{x[0].shape}\")\n",
    "print(f\" shape of x[0][0]:{x[0][0].shape}\")\n",
    "print(f\" shape of x[0][0][0]:{x[0][0][0].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3299018-39d1-4b01-999a-be662b1e477f",
   "metadata": {},
   "source": [
    "### Flatten and reshape\n",
    "\n",
    "There are various methods for reshaping tensors. It is common to have to express 2D data in 1D format. Similarly, it is also common to have to reshape a 1D tensor into a 2D tensor. We can achieve this with the .flatten() and .reshape() methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7a1fabf0-7d9a-4550-996a-6d37dfe40213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of z:torch.Size([12])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = torch.arange(12)\n",
    "print(f\"shape of z:{z.shape}\")\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "49fce7a2-30b6-4d42-8d9e-ad8c6d34224e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of z:torch.Size([6, 2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1],\n",
       "        [ 2,  3],\n",
       "        [ 4,  5],\n",
       "        [ 6,  7],\n",
       "        [ 8,  9],\n",
       "        [10, 11]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reshaping z\n",
    "z = z.reshape(6,2)\n",
    "print(f\"shape of z:{z.shape}\")\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c4e3a078-5d95-4e5d-9490-d28428f631c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of z:torch.Size([12])\n",
      "Flattened z: \n",
      " tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])\n"
     ]
    }
   ],
   "source": [
    "# 2D -> 1D\n",
    "z = z.flatten()\n",
    "print(f\"shape of z:{z.shape}\")\n",
    "print(f\"Flattened z: \\n {z}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ceeb124e-c523-4b6c-ba8d-5ba8c42f640c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of z:torch.Size([3, 4])\n",
      "Reshaped (3x4) z: \n",
      " tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11]])\n"
     ]
    }
   ],
   "source": [
    "# and back to 2D\n",
    "z = z.reshape(3, 4)\n",
    "print(f\"shape of z:{z.shape}\")\n",
    "print(f\"Reshaped (3x4) z: \\n {z}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4817a28-7fa2-4a3c-a110-845bfec4337d",
   "metadata": {},
   "source": [
    "You will also see the .view() methods used a lot to reshape tensors. There is a subtle difference between .view() and .reshape(), though for now we will just use .reshape()."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ccb921-72e7-4d0c-9488-a4dad467045d",
   "metadata": {},
   "source": [
    "### Squeezing tensors\n",
    "\n",
    "When processing batches of data, you will quite often be left with singleton dimensions. E.g., [1,10] or [256, 1, 3]. \n",
    "\n",
    "This dimension can quite easily mess up your matrix operations if you don’t plan on it being there.\n",
    "\n",
    "In order to compress tensors along their singleton dimensions we can use the .squeeze() method. We can use the .unsqueeze() method to do the opposite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8db4d289-391d-42a2-bbb9-e47747c55217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1120, -0.3482, -1.2162,  0.9048, -0.3318, -0.8544,  0.4216, -0.3407,\n",
      "          2.2298, -0.3475]])\n",
      " shape of x:torch.Size([1, 10])\n",
      "\n",
      "x[0]: tensor([ 0.1120, -0.3482, -1.2162,  0.9048, -0.3318, -0.8544,  0.4216, -0.3407,\n",
      "         2.2298, -0.3475])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1, 10)\n",
    "print(x)\n",
    "print(f\" shape of x:{x.shape}\\n\")\n",
    "\n",
    "# printing the zeroth element of the tensor will not give us the first number!\n",
    "print(f\"x[0]: {x[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21554202-b4e9-4712-8d64-9ae0efdb4ae3",
   "metadata": {},
   "source": [
    "Because of that pesky singleton dimension, x[0] gave us the first row instead!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "86e9a8e8-592b-451d-b557-546b5901660b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.1120, -0.3482, -1.2162,  0.9048, -0.3318, -0.8544,  0.4216, -0.3407,\n",
      "         2.2298, -0.3475])\n",
      " shape of x after removing dimension:torch.Size([10])\n",
      "\n",
      "x[0]: 0.11200101673603058\n"
     ]
    }
   ],
   "source": [
    "# Let's get rid of that singleton dimension and see what happens now\n",
    "x = x.squeeze(dim=0)\n",
    "print(x)\n",
    "print(f\" shape of x after removing dimension:{x.shape}\\n\")\n",
    "print(f\"x[0]: {x[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3e6faa0f-bcd1-4001-84ef-744d1a00c43e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.9925,  0.9772, -0.9462, -0.6351, -0.1659],\n",
      "        [ 0.4342,  0.1210,  0.6499, -0.1199,  0.6560],\n",
      "        [-0.3157,  0.4387, -1.3532,  0.4942, -0.6562],\n",
      "        [-0.2433, -1.1493, -2.1141,  0.2158,  0.6278],\n",
      "        [ 0.3916, -1.5136, -0.5789, -0.1252,  1.7774]])\n",
      "Shape of y: torch.Size([5, 5])\n",
      "\n",
      "Shape of y after adding dimension: torch.Size([5, 1, 5])\n"
     ]
    }
   ],
   "source": [
    "# Adding singleton dimensions works a similar way, and is often used when tensors\n",
    "# being added need same number of dimensions\n",
    "\n",
    "y = torch.randn(5, 5)\n",
    "print(y)\n",
    "print(f\"Shape of y: {y.shape}\\n\")\n",
    "\n",
    "# lets insert a singleton dimension\n",
    "y = y.unsqueeze(dim=1)\n",
    "print(f\"Shape of y after adding dimension: {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96b6247-b645-4484-a453-6173ef550afc",
   "metadata": {},
   "source": [
    "### Permutation\n",
    "\n",
    "Sometimes our dimensions will be in the wrong order! For example, we may be dealing with RGB images with dim [3 x 48 x 64], but our pipeline expects the colour dimension to be the last dimension, i.e., [48 x 64 x 3]\n",
    ". To get around this we can use the .permute() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "75a05d30-3746-440c-8ad2-f16aa1b3494d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " shape of x:torch.Size([3, 48, 64])\n",
      "\n",
      " shape of x after changing the dimensions order: torch.Size([48, 64, 3])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# `x` has dimensions [color,image_height,image_width]\n",
    "x = torch.rand(3, 48, 64)\n",
    "print(f\" shape of x:{x.shape}\\n\")\n",
    "\n",
    "# We want to permute our tensor to be [ image_height , image_width , color ]\n",
    "x = x.permute(1, 2, 0)\n",
    "\n",
    "# permute(1,2,0) means:\n",
    "# The 0th dim of my new tensor = the 1st dim of my old tensor\n",
    "# The 1st dim of my new tensor = the 2nd\n",
    "# The 2nd dim of my new tensor = the \n",
    "print(f\" shape of x after changing the dimensions order: {x.shape}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93fa7a63-0f77-4ad9-b717-f06635adab6b",
   "metadata": {},
   "source": [
    "You may also see .transpose() used. This works in a similar way as permute, but can only swap two dimensions at once."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc33987-253f-4bc0-97da-4367103b9c25",
   "metadata": {},
   "source": [
    "### Concatenation\n",
    "\n",
    "In this example, we concatenate two matrices along rows (axis 0, the first element of the shape) vs. columns (axis 1, the second element of the shape). \n",
    "\n",
    "We can see that the first output tensor’s axis-0 length (6) is the sum of the two input tensors’ axis-0 lengths (3+3); \n",
    "\n",
    "While the second output tensor’s axis-1 length (8) is the sum of the two input tensors’ axis-1 lengths (4+4)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e2e56f29-2a89-4f30-abb3-429ffe2bc439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.,  1.,  2.,  3.],\n",
      "        [ 4.,  5.,  6.,  7.],\n",
      "        [ 8.,  9., 10., 11.]])\n",
      " shape of x:torch.Size([3, 4])\n",
      "\n",
      "tensor([[2., 1., 4., 3.],\n",
      "        [1., 2., 3., 4.],\n",
      "        [4., 3., 2., 1.]])\n",
      " shape of y:torch.Size([3, 4])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create two tensors of the same shape\n",
    "x = torch.arange(12, dtype=torch.float32).reshape((3, 4))\n",
    "y = torch.tensor([[2.0, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]])\n",
    "print(x)\n",
    "print(f\" shape of x:{x.shape}\\n\")\n",
    "print(y)\n",
    "print(f\" shape of y:{y.shape}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "faaf591c-0518-46fc-846e-8ff045a96aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenated by rows, shape: torch.Size([6, 4]) \n",
      " tensor([[ 0.,  1.,  2.,  3.],\n",
      "        [ 4.,  5.,  6.,  7.],\n",
      "        [ 8.,  9., 10., 11.],\n",
      "        [ 2.,  1.,  4.,  3.],\n",
      "        [ 1.,  2.,  3.,  4.],\n",
      "        [ 4.,  3.,  2.,  1.]])\n"
     ]
    }
   ],
   "source": [
    "# Concatenate along rows\n",
    "cat_rows = torch.cat((x, y), dim=0)\n",
    "print(f\"Concatenated by rows, shape: {cat_rows.shape} \\n {cat_rows}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d31d309d-bce6-4c97-916a-226ee9f91c60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenated by columns, shape: torch.Size([3, 8]) \n",
      " tensor([[ 0.,  1.,  2.,  3.,  2.,  1.,  4.,  3.],\n",
      "        [ 4.,  5.,  6.,  7.,  1.,  2.,  3.,  4.],\n",
      "        [ 8.,  9., 10., 11.,  4.,  3.,  2.,  1.]])\n"
     ]
    }
   ],
   "source": [
    "# Concatenate along columns\n",
    "cat_cols = torch.cat((x, y), dim=1)\n",
    "print(f\"Concatenated by columns, shape: {cat_cols.shape} \\n {cat_cols}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e272f90b-fd52-41bf-bc4a-0f23ce3a7983",
   "metadata": {},
   "source": [
    "### Conversion to Other Python Objects\n",
    "\n",
    "Converting a tensor to a numpy.ndarray, or vice versa, is easy, and the converted result does not share memory. This minor inconvenience is quite important: when you perform operations on the CPU or GPUs, you do not want to halt computation, waiting to see whether the NumPy package of Python might want to be doing something else with the same chunk of memory.\n",
    "\n",
    "When converting to a NumPy array, the information being tracked by the tensor will be lost, i.e., the computational graph. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e029be49-5e2b-461d-b417-b71e0e0c27a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor([-0.9612, -1.3004, -0.9955, -0.1614,  1.0023])  |  x type:  torch.FloatTensor\n",
      "y: [-0.9612143  -1.3004     -0.99553746 -0.16137064  1.002297  ]  |  y type:  <class 'numpy.ndarray'>\n",
      "z: tensor([-0.9612, -1.3004, -0.9955, -0.1614,  1.0023])  |  z type:  torch.FloatTensor\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(5)\n",
    "print(f\"x: {x}  |  x type:  {x.type()}\")\n",
    "\n",
    "y = x.numpy()\n",
    "print(f\"y: {y}  |  y type:  {type(y)}\")\n",
    "\n",
    "z = torch.tensor(y)\n",
    "print(f\"z: {z}  |  z type:  {z.type()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb193db-ec88-4e47-a485-552f27af7954",
   "metadata": {},
   "source": [
    "To convert a size-1 tensor to a Python scalar, we can invoke the item function or Python’s built-in functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b71abcb0-81f1-4c1c-bddc-57f5413ff175",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([3.5000]), 3.5, 3.5, 3)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([3.5])\n",
    "a, a.item(), float(a), int(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69fbe71-9acb-4785-a72d-1173013bda00",
   "metadata": {},
   "source": [
    "torch.numel() is an easy way of finding the number of elements in a tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "64e64a44-fcaa-4317-bd0d-d6ee0dca80c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  2.,  3.],\n",
       "        [ 4.,  5.,  6.,  7.],\n",
       "        [ 8.,  9., 10., 11.],\n",
       "        [ 2.,  1.,  4.,  3.],\n",
       "        [ 1.,  2.,  3.,  4.],\n",
       "        [ 4.,  3.,  2.,  1.]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2eb20610-1a38-4ae2-a06c-74620194c446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_elements = torch.numel(cat_rows)\n",
    "n_elements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ac5c7b-28ea-4086-8270-33ad829437f8",
   "metadata": {},
   "source": [
    "## Exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f02e5cda-ddca-47b3-a9da-91422f4d5bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def functionA(my_tensor1, my_tensor2):\n",
    "      \"\"\"\n",
    "      This function takes in two 2D tensors `my_tensor1` and `my_tensor2`\n",
    "      and returns the column sum of\n",
    "      `my_tensor1` multiplied by the sum of all the elmements of `my_tensor2`,\n",
    "      i.e., a scalar.\n",
    "    \n",
    "      Args:\n",
    "        my_tensor1: torch.Tensor\n",
    "        my_tensor2: torch.Tensor\n",
    "    \n",
    "      Retuns:\n",
    "        output: torch.Tensor\n",
    "          The multiplication of the column sum of `my_tensor1` by the sum of\n",
    "          `my_tensor2`.\n",
    "      \"\"\"\n",
    "      ################################################\n",
    "      ## TODO for students: complete functionA\n",
    "      # raise NotImplementedError(\"Student exercise: complete function A\")\n",
    "      ################################################\n",
    "      # TODO multiplication the sum of the tensors\n",
    "      output = my_tensor1.sum(dim=1) * my_tensor2.sum(dim=None)\n",
    "    \n",
    "      return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c4e36e8-c964-4b7c-83a2-bdab24e83346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([24, 24])\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    functionA(\n",
    "    torch.tensor([[1, 1], [1, 1]]), \n",
    "    torch.tensor([[1, 2, 3], [1, 2, 3]])\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e696ce31-0d86-4051-941b-333db02cb9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = torch.tensor([[1, 1], [1, 1]])\n",
    "# a\n",
    "\n",
    "# b = torch.tensor([[1, 2, 3], [1, 2, 3]])\n",
    "# b\n",
    "\n",
    "# # column sum\n",
    "# a_sum = a.sum(dim=1)\n",
    "# a_sum\n",
    "\n",
    "# # sum of all elements of b\n",
    "# b_sum = b.sum()\n",
    "# b_sum\n",
    "\n",
    "# a_sum * b_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c4158b-ecb9-4dae-9da0-3b7411185a09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4ba226cd-0a00-4f5d-92f0-81f979be5360",
   "metadata": {},
   "outputs": [],
   "source": [
    "def functionB(my_tensor):\n",
    "    \"\"\"\n",
    "    This function takes in a square matrix `my_tensor` and returns a 2D tensor\n",
    "    consisting of a flattened `my_tensor` with the index of each element\n",
    "    appended to this tensor in the row dimension.\n",
    "    \n",
    "    Args:\n",
    "    my_tensor: torch.Tensor\n",
    "    \n",
    "    Returns:\n",
    "    output: torch.Tensor\n",
    "      Concatenated tensor.\n",
    "    \"\"\"\n",
    "    ################################################\n",
    "    ## TODO for students: complete functionB\n",
    "    # raise NotImplementedError(\"Student exercise: complete function B\")\n",
    "    ################################################\n",
    "    # TODO flatten the tensor `my_tensor`\n",
    "    my_tensor = my_tensor.flatten()\n",
    "    # TODO create the idx tensor to be concatenated to `my_tensor`\n",
    "    idx_tensor = torch.arange(torch.numel(my_tensor))\n",
    "    # TODO concatenate the two tensors\n",
    "    my_tensor = my_tensor.unsqueeze(dim=1)\n",
    "    idx_tensor = idx_tensor.unsqueeze(dim=1)\n",
    "    output = torch.cat((idx_tensor,my_tensor), dim=1)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ee00710b-aa31-4348-9319-d11ef44929ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  2],\n",
      "        [ 1,  3],\n",
      "        [ 2, -1],\n",
      "        [ 3, 10]])\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    functionB(\n",
    "        torch.tensor([[2, 3], [-1, 10]])\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3704641e-51ea-4d52-93f6-b2da227e133a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = torch.tensor([[2, 3], [-1, 10]])\n",
    "# a\n",
    "\n",
    "# # flattening\n",
    "# a_flat = a.flatten()\n",
    "# # creating column matrix\n",
    "# a_flat_col = a_flat.unsqueeze(dim=1)\n",
    "# a_flat_col\n",
    "\n",
    "# # finding total elements in a\n",
    "# n_elements = torch.numel(a)\n",
    "# # creating a 1 dim matrix with the elements\n",
    "# a_ind = torch.arange(n_elements)\n",
    "# # creating a 2 dim matrix by adding a column\n",
    "# a_ind_col = a_ind.unsqueeze(dim=1)\n",
    "# a_ind_col\n",
    "\n",
    "# # concatenating the column matrices\n",
    "# final_a = torch.concat((a_ind_col, a_flat_col), dim=1)\n",
    "# final_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "d7af358a-1f37-4c7d-88fb-0c77c5f72756",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "51a72c6d-2eb0-4209-a718-e2d3c1a8eb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def functionC(my_tensor1, my_tensor2):\n",
    "  \"\"\"\n",
    "  This function takes in two 2D tensors `my_tensor1` and `my_tensor2`.\n",
    "  If the dimensions allow it, it returns the\n",
    "  elementwise sum of `my_tensor1`-shaped `my_tensor2`, and `my_tensor2`;\n",
    "  else this function returns a 1D tensor that is the concatenation of the\n",
    "  two tensors.\n",
    "\n",
    "  Args:\n",
    "    my_tensor1: torch.Tensor\n",
    "    my_tensor2: torch.Tensor\n",
    "\n",
    "  Returns:\n",
    "    output: torch.Tensor\n",
    "      Concatenated tensor.\n",
    "  \"\"\"\n",
    "  ################################################\n",
    "  ## TODO for students: complete functionB\n",
    "  # raise NotImplementedError(\"Student exercise: complete function C\")\n",
    "  ################################################\n",
    "  # TODO check we can reshape `my_tensor2` into the shape of `my_tensor1`\n",
    "  if torch.numel(my_tensor1) == torch.numel(my_tensor2):\n",
    "    # TODO reshape `my_tensor2` into the shape of `my_tensor1`\n",
    "    my_tensor2 = my_tensor2.reshape(my_tensor1.shape)\n",
    "    # TODO sum the two tensors\n",
    "    output = my_tensor1 + my_tensor2\n",
    "  else:\n",
    "    # TODO flatten both tensors\n",
    "    my_tensor1 = my_tensor1.flatten()\n",
    "    my_tensor2 = my_tensor2.flatten()\n",
    "    # TODO concatenate the two tensors in the correct dimension\n",
    "    output = torch.cat((my_tensor1, my_tensor2), dim=0)\n",
    "\n",
    "  return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "785bddd7-af64-4962-bfe4-f32d91829516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 3,  2],\n",
      "        [-1,  5]])\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    functionC(\n",
    "        torch.tensor([[1, -1], [-1, 3]]), \n",
    "        torch.tensor([[2, 3, 0, 2]])\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4f9c0902-ad03-4655-9867-042b7c5ac50f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1, -1, -1,  3,  2,  3,  0])\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    functionC(\n",
    "        torch.tensor([[1, -1], [-1, 3]]), \n",
    "        torch.tensor([[2, 3, 0]])\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2e2c3783-3c1c-467f-a1f9-aeb457fc3539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# d = torch.tensor([[1, -1], [-1, 3]])\n",
    "# d\n",
    "\n",
    "# e = torch.tensor([[2, 3, 0, 2]])\n",
    "# e\n",
    "\n",
    "# ## lementwise sum of d shaped e\n",
    "# # reshaping e\n",
    "# e = e.reshape(d.shape)\n",
    "# e\n",
    "\n",
    "# # elementwise sum\n",
    "# s = d + e\n",
    "# s\n",
    "\n",
    "# d\n",
    "\n",
    "# e = torch.tensor([[2, 3, 0]])\n",
    "# e.shape\n",
    "\n",
    "# e.squeeze(dim=0)\n",
    "\n",
    "# if d.shape != e.shape:\n",
    "#     d = d.flatten()\n",
    "#     e = e.flatten()\n",
    "#     con = torch.cat((d,e), dim=0)\n",
    "# con"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e248677-2a77-42a0-b9dd-f5659a16a40b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be44536e-33a7-4f3a-95be-8ec2a69902a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe309f61-8810-4638-af98-2edf6fbd77d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0376bbdc-e5f9-4188-8bd1-999e85029b17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e0f7ea-4f86-4692-b60b-bab07e9e3deb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6d3865-6036-4d60-bab2-f7795c1e624c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c513b7c7-e0c3-4ed4-b48b-8043b0fcbab5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
